#!/usr/bin/env python3
"""
POC 1 - Optimized Whisper Transcription Pipeline Test

æ¸¬è©¦å®Œæ•´çš„ VAD + æ™ºèƒ½åˆ†æ®µ + ä¸¦è¡Œè½‰éŒ„å„ªåŒ–æµç¨‹
"""

import sys
import logging
import argparse
import json
import time
from pathlib import Path

# åŠ å…¥ src è·¯å¾‘
sys.path.insert(0, str(Path(__file__).parent.parent.parent.parent.parent / "src"))

from transcription.pipeline import OptimizedTranscriptionPipeline


def setup_logging(verbose: bool = False):
    """è¨­å®šæ—¥èªŒ"""
    level = logging.DEBUG if verbose else logging.INFO

    logging.basicConfig(
        level=level,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
        handlers=[
            logging.FileHandler('optimized_pipeline_test.log'),
            logging.StreamHandler()
        ]
    )


def test_optimized_pipeline(
    audio_path: str,
    model_size: str = "medium",
    device: str = "cpu",
    workers: int = 6,
    vad_preset: str = "meeting",
    output_dir: str = None,
    enable_diarization: bool = False,
    diarization_token: str = None,
    diarization_model: str = "pyannote/speaker-diarization",
    diarization_allow_overlap: bool = False,
) -> dict:
    """
    æ¸¬è©¦å„ªåŒ–çš„è½‰éŒ„æµç¨‹

    Args:
        audio_path: éŸ³æª”è·¯å¾‘
        model_size: æ¨¡å‹å¤§å°
        device: è¨­å‚™
        workers: ä¸¦è¡Œå·¥ä½œæ•¸
        vad_preset: VAD é è¨­é…ç½®
        output_dir: è¼¸å‡ºç›®éŒ„

    Returns:
        dict: æ¸¬è©¦çµæœ
    """
    logger = logging.getLogger(__name__)

    logger.info("="*80)
    logger.info("POC 1 - OPTIMIZED WHISPER TRANSCRIPTION PIPELINE TEST")
    logger.info("="*80)

    # å»ºç«‹ pipeline
    logger.info("\nInitializing pipeline...")
    pipeline = OptimizedTranscriptionPipeline(
        model_size=model_size,
        device=device,
        max_workers=workers,
        vad_preset=vad_preset,
        output_dir=output_dir,
        target_chunk_duration=600,  # 10åˆ†é˜ç‰‡æ®µ
        overlap_duration=2,
        language="zh",
        enable_diarization=enable_diarization,
        diarization_auth_token=diarization_token,
        diarization_model=diarization_model,
        diarization_allow_overlap=diarization_allow_overlap,
    )

    # åŸ·è¡Œè½‰éŒ„
    logger.info("\nStarting transcription...")
    start_time = time.time()

    result = pipeline.process_audio(
        audio_path=audio_path,
        save_transcription=True,
        output_formats=["txt", "json", "srt"]
    )

    total_time = time.time() - start_time

    # ç”Ÿæˆæ¸¬è©¦å ±å‘Š
    test_result = generate_test_report(result, total_time, audio_path, model_size)

    return test_result


def generate_test_report(
    result: dict,
    total_time: float,
    audio_path: str,
    model_size: str
) -> dict:
    """ç”Ÿæˆæ¸¬è©¦å ±å‘Š"""
    logger = logging.getLogger(__name__)

    logger.info("\n" + "="*80)
    logger.info("TEST REPORT")
    logger.info("="*80)

    if not result["success"]:
        logger.error(f"Transcription FAILED: {result.get('error', 'Unknown error')}")
        return {
            "success": False,
            "error": result.get("error"),
            "audio_path": audio_path
        }

    # æå–çµ±è¨ˆè³‡è¨Š
    stats = result["statistics"]
    audio_info = result["audio_info"]
    config = result["pipeline_config"]

    diarization_enabled = config.get("diarization_enabled", False)
    diarization_error = result.get("diarization_error")

    audio_duration = audio_info["duration"]
    audio_size_mb = audio_info["size"] / (1024 * 1024)
    processing_time = result["pipeline_total_time"]
    speed_ratio = processing_time / audio_duration

    # è¨ˆç®—å“è³ªæŒ‡æ¨™ï¼ˆåŸºæ–¼ segment æ•¸é‡å’Œæ–‡å­—é•·åº¦çš„å•Ÿç™¼å¼è©•ä¼°ï¼‰
    expected_segments = int(audio_duration / 5)  # å‡è¨­å¹³å‡æ¯ 5 ç§’ä¸€å€‹ segment
    segment_ratio = stats["total_segments"] / expected_segments if expected_segments > 0 else 0
    quality_score = min(100, segment_ratio * 100)  # ç°¡åŒ–çš„å“è³ªè©•åˆ†

    # åˆ¤æ–·æ˜¯å¦é€šé
    target_speed_ratio = 0.5  # ç›®æ¨™æ˜¯è™•ç†æ™‚é–“ < éŸ³æª”æ™‚é•·çš„ 50%
    passed = speed_ratio < target_speed_ratio and quality_score > 70

    # åˆ—å°å ±å‘Š
    logger.info(f"\nğŸ“ Audio File:")
    logger.info(f"   Path: {audio_path}")
    logger.info(f"   Duration: {audio_duration:.1f}s ({audio_duration/60:.1f} min)")
    logger.info(f"   Size: {audio_size_mb:.2f} MB")

    logger.info(f"\nâš™ï¸  Configuration:")
    logger.info(f"   Model: {model_size}")
    logger.info(f"   Device: {config['device']}")
    logger.info(f"   Workers: {config['max_workers']}")
    logger.info(f"   VAD Enabled: {config['vad_enabled']}")
    logger.info(f"   Chunks: {config['chunk_count']}")

    logger.info(f"\nâ±ï¸  Performance:")
    logger.info(f"   Processing Time: {processing_time:.1f}s ({processing_time/60:.1f} min)")
    logger.info(f"   Speed Ratio: {speed_ratio:.3f}x")

    if speed_ratio < 1.0:
        speedup = 1.0 / speed_ratio
        logger.info(f"   Speedup: {speedup:.2f}x faster than real-time")
    else:
        logger.info(f"   Speedup: {speed_ratio:.2f}x slower than real-time")

    time_saved = audio_duration - processing_time
    logger.info(f"   Time Saved: {time_saved:.1f}s ({time_saved/60:.1f} min)")

    logger.info(f"\nğŸ“Š Output:")
    logger.info(f"   Total Segments: {stats['total_segments']}")
    logger.info(f"   Text Length: {len(result['full_text'])} characters")
    logger.info(f"   Quality Score: {quality_score:.1f}%")

    logger.info(f"\nğŸ“ Text Preview (first 200 chars):")
    logger.info(f"   {result['full_text'][:200]}...")

    speaker_summary = result.get("speakers", [])
    if diarization_error:
        logger.warning("Speaker diarization disabled: %s", diarization_error)
    elif diarization_enabled and speaker_summary:
        logger.info(f"\nğŸ—£ï¸  Speakers Detected: {len(speaker_summary)}")
        for speaker in speaker_summary:
            speaker_time = speaker["duration"]
            logger.info(
                "   - %s: segments=%d, duration=%.1fs (%.1f min)",
                speaker["speaker"],
                int(speaker["segment_count"]),
                speaker_time,
                speaker_time / 60.0,
            )

    logger.info(f"\nâœ… Test Result:")
    if passed:
        logger.info(f"   Status: PASSED âœ“")
        logger.info(f"   Speed ratio {speed_ratio:.3f}x < target {target_speed_ratio}x")
        logger.info(f"   Quality score {quality_score:.1f}% > 70%")
    else:
        logger.warning(f"   Status: FAILED âœ—")
        if speed_ratio >= target_speed_ratio:
            logger.warning(f"   Speed ratio {speed_ratio:.3f}x >= target {target_speed_ratio}x")
        if quality_score <= 70:
            logger.warning(f"   Quality score {quality_score:.1f}% <= 70%")

    logger.info("="*80)

    # æ¯”è¼ƒèˆ‡åŸå§‹æ–¹æ¡ˆçš„å·®ç•°
    logger.info(f"\nğŸ“ˆ Comparison with Baseline (Medium model without optimization):")
    baseline_speed_ratio = 0.915  # å¾ä¹‹å‰çš„æ¸¬è©¦çµæœ
    baseline_time = audio_duration * baseline_speed_ratio
    improvement = ((baseline_time - processing_time) / baseline_time) * 100

    logger.info(f"   Baseline processing time: {baseline_time:.1f}s ({baseline_time/60:.1f} min)")
    logger.info(f"   Optimized processing time: {processing_time:.1f}s ({processing_time/60:.1f} min)")
    logger.info(f"   Improvement: {improvement:.1f}%")
    logger.info(f"   Speedup factor: {baseline_time/processing_time:.2f}x")

    logger.info("="*80)

    # æ§‹å»ºæ¸¬è©¦çµæœ
    test_result = {
        "success": True,
        "passed": passed,
        "audio_path": audio_path,
        "audio_duration": audio_duration,
        "audio_size_mb": audio_size_mb,
        "model_size": model_size,
        "processing_time": processing_time,
        "speed_ratio": speed_ratio,
        "quality_score": quality_score,
        "total_segments": stats["total_segments"],
        "text_length": len(result["full_text"]),
        "vad_enabled": config["vad_enabled"],
        "chunk_count": config["chunk_count"],
        "workers": config["max_workers"],
        "diarization_enabled": diarization_enabled,
        "diarization_error": diarization_error,
        "speakers": speaker_summary,
        "full_result": result
    }

    return test_result


def save_test_result(test_result: dict, output_file: str):
    """å„²å­˜æ¸¬è©¦çµæœ"""
    logger = logging.getLogger(__name__)

    # ç§»é™¤ full_result ä»¥æ¸›å°‘æª”æ¡ˆå¤§å°
    summary = {k: v for k, v in test_result.items() if k != "full_result"}

    with open(output_file, "w", encoding="utf-8") as f:
        json.dump(summary, f, ensure_ascii=False, indent=2)

    logger.info(f"\nTest result saved to: {output_file}")


def main():
    """ä¸»ç¨‹å¼"""
    parser = argparse.ArgumentParser(
        description="POC 1 - Optimized Whisper Transcription Pipeline Test"
    )

    parser.add_argument(
        "--audio",
        required=True,
        help="Path to audio file"
    )

    parser.add_argument(
        "--model",
        default="medium",
        choices=["tiny", "base", "small", "medium", "large-v3"],
        help="Whisper model size (default: medium)"
    )

    parser.add_argument(
        "--device",
        default="cpu",
        choices=["cpu", "cuda"],
        help="Device to use (default: cpu)"
    )

    parser.add_argument(
        "--workers",
        type=int,
        default=6,
        help="Number of parallel workers (default: 6)"
    )

    parser.add_argument(
        "--vad-preset",
        default="meeting",
        choices=["meeting", "presentation", "noisy", "default"],
        help="VAD preset configuration (default: meeting)"
    )

    parser.add_argument(
        "--output-dir",
        help="Output directory for transcription files"
    )

    parser.add_argument(
        "--output",
        default="poc1_optimized_results.json",
        help="Output file for test results (default: poc1_optimized_results.json)"
    )

    parser.add_argument(
        "--verbose",
        action="store_true",
        help="Enable verbose logging"
    )

    parser.add_argument(
        "--diarization",
        action="store_true",
        help="Enable speaker diarization"
    )

    parser.add_argument(
        "--diarization-token",
        help="Hugging Face token for pyannote.audio diarization (optional)"
    )

    parser.add_argument(
        "--diarization-model",
        default="pyannote/speaker-diarization",
        help="Speaker diarization model identifier (default: pyannote/speaker-diarization)"
    )

    parser.add_argument(
        "--allow-diarization-overlap",
        action="store_true",
        help="Keep overlapping speaker segments instead of truncating (default: disabled)"
    )

    args = parser.parse_args()

    # è¨­å®šæ—¥èªŒ
    setup_logging(args.verbose)

    logger = logging.getLogger(__name__)
    logger.info("Starting Optimized Whisper Pipeline Test...")

    # åŸ·è¡Œæ¸¬è©¦
    test_result = test_optimized_pipeline(
        audio_path=args.audio,
        model_size=args.model,
        device=args.device,
        workers=args.workers,
        vad_preset=args.vad_preset,
        output_dir=args.output_dir,
        enable_diarization=args.diarization,
        diarization_token=args.diarization_token,
        diarization_model=args.diarization_model,
        diarization_allow_overlap=args.allow_diarization_overlap
    )

    # å„²å­˜çµæœ
    save_test_result(test_result, args.output)

    # è¿”å›çµæœ
    if test_result["success"] and test_result["passed"]:
        logger.info("\nâœ… TEST PASSED")
        return 0
    elif test_result["success"]:
        logger.warning("\nâš ï¸  TEST COMPLETED BUT DID NOT MEET PERFORMANCE TARGETS")
        return 1
    else:
        logger.error("\nâŒ TEST FAILED")
        return 1


if __name__ == "__main__":
    exit(main())
